\chapter{Normalizzazione}

\section{Ridondanze e anomalie}
Per introdurre i primi concetti, utilizziamo un esempio.\\
Consideriamo una relazione $(Impiegato, Stipendio, Progetto, Bilancio, Funzione)$, avente le seguente proprietà:
    \begin{itemize}
        \item{Lo stipendio di ciascun impiegato è unico ed è funzione del solo impiegato, indipendentemente dai progetti a cui partecipa.}
        \item{Il bilancio di ciascun progetto è unico e dipende dal solo progetto, indipendentemente dagli impiegati che vi partecipano.}
    \end{itemize}
Questa relazione presenta alcune problematiche:
    \begin{itemize}
        \item{Il valore dello stipendio di ciascun impiegato è ripetuto in tutte le tuple relative ad esso: si ha quindi una \textbf{ridondanza}.}
        \item{Se lo stipendio di un impiegato varia, è necessario andarne a modificare il valore in tutte le tuple corrispondenti, affinché la dipendenza continui a valere.\\
        Questo inconveniente, che comporta la necessità di effettuare più modifiche contemporaneamente, va sotto il nome di \textbf{anomalia di aggiornamento}.}
        \item{Se un impiegato interrompe la partecipazione a tutti i progetti senza lasciare l'azienda, e quindi tutte le corrispondenti tuple vengono eliminate, non è possibile conservare traccia del suo nome e del suo stipendio (a meno di ammettere valori nulli sull'unica chiave, il che è inammissibile), che potrebbero rimanere di interesse.\\
        Questo problema viene indicato come \textbf{anomalia di cancellazione}.}
        \item{Analogamente, se si hanno informazioni su un nuovo impiegato, non è possibile inserirle finché questi non viene assegnato a un progetto; in questo caso parliamo di \textbf{anomalia di inserimento}.}
    \end{itemize}
Una motivazione intuitiva della presenza di questi inconvenienti può essere la seguente: abbiamo usato un'unica relazione per rappresentare informazioni eterogenee.\\
Generalizzando, possiamo arrivare alle seguenti conclusioni, che evidenziano i difetti presentati da relazioni che riuniscono concetti fra loro disomogenei:
    \begin{itemize}
        \item{È possibile che alcuni dati debbano essere ripetuti in diverse tuple, senza aggiungere in tal modo informazioni significative.}
        \item{Se alcune informazioni sono ripetute in modo ridondante, il relativo aggiornamento (concettualmente atomico) deve essere ripetuto per ciascuna occorrenza dei relativi dati.\\
        Il fatto che i linguaggi di manipolazione, per esempio SQL, permettano aggiornamenti multipli risolve il problema solo dal punto di vista del programmatore ma non da quello del sistema, perché comunque le tuple della base di dati vanno aggiornate tutte e quindi si deve fisicamente accedere a ciascuna di esse.}
        \item{La cancellazione di una tupla, motivata dal fatto che non è più valido l'intero insieme di concetti da essa espressi, per esempio perché uno di essi non sussiste più, può comportare l'eliminazione di tutti i concetti in questione, cioè anche di quelli che conservano la loro validità.}
        \item{L'inserimento di informazioni relative a uno solo dei concetti di pertinenza per una relazione non è possibile se non esiste un intero insieme di concetti in grado di costruire una tupla completa (o almeno la sua chiave primaria).}
    \end{itemize}

\section{Dipendenze funzionali}
La \textbf{dipendenza funzionale} è un particolare vincolo di integrità per il modello relazionale, che descrive legami di tipo funzionale tra gli attributi di una relazione.\\\\
Data una relazione $r$ su uno schema $R(X)$ e due sottoinsiemi di attributi non vuoti $Y$ e $Z$ di $X$, diremo che esiste su $r$ una \textbf{dipendenza funzionale fra} $Y$ e $Z$ se, per ogni coppia di tuple $t_1, t_2$ di $r$ aventi gli stessi valori sugli attributi $Y$, risulta che $t_1$ e $t_2$ hanno gli stessi valori anche sugli attributi $Z$.\\
Una dipendenza funzionale tra gli attributi $Y$ e $Z$ viene generalmente indicata con la notazione $Y \rightarrow Z$ e, come gli altri vincoli di integrità, viene associata a uno schema: una relazione su quello schema verrà considerata corretta se soddisfa tale dipendenza funzionale.\\\\
Ci sono alcune osservazioni da fare:
    \begin{enumerate}
        \item{Se l'insieme $Z$ è composto dagli attributi $A_1, ..., A_k$, allora una relazione soddisfa $Y \rightarrow Z$ se e solo se esso soddisfa tutte le $k$ dipendenze $Y \rightarrow A_1, ..., Y \rightarrow A_k$.\\
        Quindi, possiamo assumere che le dipendenze abbiano la forma $Y \rightarrow A$, in cui $A$ è un singolo attributo.}
        \item{Una dipendenza funzionale $Y \rightarrow A$ è \textbf{non banale} se $A$ non compare tra gli attributi di $Y$.}
        \item{Se prendiamo una chiave $K$ di una relazione $r$, si può facilmente verificare che esiste una dipendenza funzionale tra $K$ e ogni altro attributo dello schema di $r$.\\
        Questo perché, per definizione stessa di vincolo di chiave, non possono esistere due tuple con gli stessi valori su $K$ e quindi una dipendenza funzionale che ha $K$ al primo membro sarà sempre soddisfatta.}
        \item{Il vincolo di dipendenza funzionale \textbf{generalizza} il vincolo di chiave. Più precisamente, possiamo dire che una dipendenza funzionale $Y \rightarrow Z$ su uno schema $R(X)$ degenera nel vincolo di chiave se l'unione di $Y$ e $Z$ è pari $X$.}
    \end{enumerate}

\section{Teoria di Armstrong}
La teoria di Armstrong ci permette di verificare le equivalenze senza ricorrere alla definizione di vincolo di dipendenza funzionale.

\subsection{Assiomi della teoria di Armstrong}
\textbf{Riflessività}
    \begin{equation}\begin{aligned}
        \text{Se } Y \subseteq X \text{ allora } X \rightarrow Y
    \end{aligned}\end{equation}
\textbf{Unione}
    \begin{equation}\begin{aligned}
        \text{Se } 
            X \rightarrow Y 
            \text{ e } X \rightarrow Z 
            \text{ allora } X \rightarrow YZ\\
        \text{Dove }  YZ = Y \cup Z
    \end{aligned}\end{equation}
\textbf{Transitività}
    \begin{equation}\begin{aligned}
        \text{Se } 
            X \rightarrow Y 
            \text{ e } Y \rightarrow Z 
            \text{ allora } X \rightarrow Z
    \end{aligned}\end{equation}
    
\subsection{Vincolo di dipendenza funzionale}
Il vincolo della dipendenza funzionale è un modello (in senso matematico) della teoria di Armstrong.\\
Un modello calza su una teoria quando gli assiomi della teoria sono rispettati dal modello.\\\\
La teoria di Armstrong, dal punto di vista del modello dei vincoli delle dipendenze funzionali è una teoria corretta: posso quindi applicare i teoremi della teoria di Armstrong al modello dei vincoli di dipendenza funzionale.

\subsubsection{Teorema dell'espansione}
Data una dipendenza funzionale $X \rightarrow Y$ e un insieme di attributi $W$, allora:
    $$WX \rightarrow WY$$

\subsubsection{Teorema di decomposizione}
Data una dipendenza funzionale $X \rightarrow YZ$, allora
    $$X \rightarrow Y \wedge X \rightarrow Z$$

\subsubsection{Teorema di pseudo-transitività}
Date $X \rightarrow Y$, $WY \rightarrow Z$, allora 
    $$WX \rightarrow Z$$

\subsubsection{Teorema del prodotto}
Date le dipendenze funzionali $X \rightarrow Y$ e $W \rightarrow Z$, allora 
    $$WX \rightarrow YZ$$

\subsection{Attributi estranei}
Abbiamo le seguenti dipendenze funzionali $F$:
    \begin{equation}\begin{aligned}
        ABCD \rightarrow E\\
        B \rightarrow C
    \end{aligned}\end{equation}
Allora, $C$ è un attributo estraneo e si può cancellare dalla prima dipendenza, che diventa $ABD \rightarrow E$.


\section{Forma normale di Boyce e Codd}
\subsection{Definizione di forma normale di Boyce e Codd}
Possiamo introdurre delle proprietà, dette \textbf{forme normali}, definite con riferimento alle dipendenze funzionali, che sono soddisfatte \textit{quando non ci sono anomalie}.\\\\
Le ridondanze e le anomalie sono causate delle dipendenze funzionali $X \rightarrow A$ che permettono la presenza di più tuple tra loro uguali sugli attributi in $X$, cioè dalle dipendenze funzionali $X \rightarrow A$ tali che $X$ non contiene una chiave.\\
Precisiamo questa considerazione per mezzo della più importante delle forme normali, detta di Boyce e Codd: una relazione $r$ è \textbf{in forma normale di Boyce e Codd} se, per ogni dipendenza funzionale (non banale) $X \rightarrow A$ definita su di essa, $X$ contiene una chiave $K$ di $r$, cioè $X$ è superchiave per $r$.\\\\
Anomalie e ridondanze non si presentano per relazioni in forma normale di Boyce e Codd, perché i concetti indipendenti sono separati, uno per relazione.

\subsection{Decomposizione in forma normale di Boyce e Codd}
Data una relazione che non soddisfa la forma normale di Boyce e Codd è possibile, in molti casi, sostituirla con due o più relazioni normalizzate attraverso un processo detto di \textbf{normalizzazione}.\\
Questo processo si fonda su un semplice criterio: se una relazione rappresenta più concetti indipendenti, allora va decomposta in relazioni più piccole, una per ogni concetto.\\\\
In molti casi pratici, la decomposizione può essere effettuata producendo tante relazioni quante sono le dipendenze funzionali definite (o meglio, le dipendenze funzionali con diverso primo membro).

\section{Proprietà delle decomposizioni}
\subsection{Decomposizione senza perdita}
Data una relazione $r$ su un insieme di attributi $X$, se $X_1$ e $X_2$ sono due sottoinsiemi di $X$ la cui unione sia pari a $X$ stesso, allora il join delle due relazioni ottenute per proiezione da $r$ su $X_1$ e $X_2$, rispettivamente, è una relazione che contiene tutte le tuple di $r$, più eventualmente altre, che possiamo chiamare \textit{spurie}.\\\\
Diciamo che $r$ si \textbf{decompone senza perdita} su $X_1$ e $X_2$ se il join delle due proiezioni è uguale a $r$ stessa (cioè non contiene tuple spurie).\\
È chiaramente desiderabile, anzi, è un requisito irrinunciabile, che una decomposizione effettuata a fini di normalizzazione sia senza perdita.\\\\
È possibile individuare una condizione che garantisce la decomposizione senza perdita di una relazione.\\ 
Sia $r$ una relazione su $X$ e siano $X_1$ e $X_2$ sottoinsiemi di $X$ tali che $X_1 \cup X_2 = X$, e sia $X_0 = X_1 \cap X_2$. Allora, $r$ si decompone senza perdita su $X_1$ e $X_2$ se soddisfa la dipendenza funzionale $X_0 \rightarrow X_1$ oppure la dipendenza funzionale $X_0 \rightarrow X_2$.\\
In altre parole, $r$ si decompone senza perdita su due relazioni se l'insieme degli attributi comuni alle due relazioni è chiave per almeno una delle relazioni decomposte.\\\\
Questa condizione è sufficiente ma non necessaria per la decomposizione senza perdita: esistono, infatti, istanze di relazione che non soddisfano nessuna delle due dipendenze, ma al tempo stesso si decompongono senza perdita.\\
Al tempo stesso, la condizione in questione che tutte le istanze di relazione che soddisfano un dato insieme di dipendenze si decompongano senza perdita, e questo è un risultato utilizzabile in pratica: quando decomponiamo una relazione in due parti, se l'insieme degli attributi comuni è chiave per una delle due relazioni, allora possiamo essere certi che tutte le istanze della relazione si decompongono senza perdita.

\subsection{Conservazione delle dipendenze}
In ogni decomposizione, ciascuna delle dipendenze funzionali dello schema originario dovrebbe coinvolgere attributi che compaiono tutti insieme in uno degli schemi decomposti.\\
In questo modo è possibile garantire, sullo schema decomposto, il soddisfacimento degli stessi vincoli il cui soddisfacimento degli stessi vincoli il cui soddisfacimento è garantito dallo schema originario.\\
Diremo che una decomposizione che soddisfa tale proprietà \textbf{conserva le dipendenze} dello schema originario.

\subsection{Qualità delle decomposizioni}
Possiamo affermare che le decomposizioni dovrebbero sempre soddisfare le proprietà di \textbf{decomposizione senza pedita} e \textbf{conservazione delle dipendenze}:
    \begin{itemize}
        \item{La \textbf{decomposizione senza pedita} garantisce che le informazioni nella relazione originaria siano ricostruibili con precisione (cioè senza informazioni spurie) a partire da quelle rappresentate nelle relazioni decomposte.\\
        In tal caso, interrogando le relazioni decomposte, otteniamo gli stessi risultati che otterremmo interrogando la relazione originaria.}
        \item{La \textbf{conservazione delle dipendenze} garantisce che le relazioni decomposte abbiano la stessa capacità della relazione originaria di rappresentare i vincoli di integrità (e cioè le proprietà della realtà di interesse) e quindi di rilevare aggiornamenti illeciti: a ogni aggiornamento lecito (rispettivamente illecito) sulla relazione originaria corrisponde un aggiornamento lecito (rispettivamente illecito) sulle relazioni decomposte.\\
        Ovviamente sono possibili sulle relazioni decomposte ulteriori aggiornamenti, legati ai singoli concetti rappresentati in ciascuna di esse, che non hanno un corrispettivo sulla relazione originaria, senza però corrispondere a violazioni dei vincoli: si tratta degli aggiornamenti impossibili sulle relazioni non normalizzate a causa delle anomalie.}
    \end{itemize}
Di conseguenza, consideriamo accettabili, cioè di qualità sufficiente, solo le decomposizioni che soddisfano queste due proprietà.\\
Dato uno schema che violi una forma normale, l'attività di normalizzazione è quindi volta a ottenere una decomposizione che sia senza perdita, che conservi le dipendenze e contenga relazioni in forma normale.

\section{Terza forma normale}
\subsection{Limitazioni della forma normale di Boyce e Codd}
In alcuni casi, la forma normale di Boyce e Codd non è raggiungibile: esistono schemi che violano la forma normale di Boyce e Codd per i quali non esiste alcuna decomposizione che conservi le dipendenze.

\subsection{Definizione di terza forma normale}
Per trattare i casi in cui la forma normale di Boyce e Codd non è raggiungibile, si ricorre a una forma normale meno restrittiva.\\
Diciamo che una relazione $r$ è in \textbf{terza forma normale} se, per ogni dipendenza funzionale non banale $X \rightarrow A$ definita su di essa, almeno una delle seguenti condizioni è verificata:
    \begin{itemize}
        \item{$X$ contiene una chiave $K$ di $r$}
        \item{$A$ appartiene ad almeno una chiave di $r$}
    \end{itemize}
In sostanza, la terza forma normale è meno forte della forma normale di Boyce e Codd e quindi non offre le medesime garanzie di qualità per una relazione; ha però, rispetto a essa il vantaggio di essere sempre ottenibile.\\
È possibile dimostrare che una qualunque relazione che non soddisfa la terza forma normale è certamente decomponibile senza perdita e con conservazione delle dipendenze in relazioni in terza forma normale.

\subsection{Decomposizione in terza forma normale}
Per decomporre una relazione in terza forma normale, si può procedere come suggerito nel caso della forma normale di Boyce e Codd: una relazione che non soddisfa la terza forma normale si decompone in relazioni ottenute per proiezione sugli attributi corrispondenti alle dipendenze funzionali, con l'unica accortezza di mantenere sempre una relazione che contiene una chiave della relazione originaria.\\\\
Una decomposizione tesa a ottenere la terza forma normale produce nella maggior parte dei casi schemi in forma normale di Boyce e Codd. In particolare, si può dimostrare che, se una relazione ha solo una chiave, allora le due forme normali coincidono, cioè una relazione in terza forma normale è anche in forma normale di Boyce e Codd.

\section{Teoria delle dipendenze e normalizzazione}
Questa sezione mostra come i più importanti concetti appena discussi possano essere formalizzati, arrivando a un processo di normalizzazione relizzabile in modo algoritmico.\\
Data una relazione e un insieme di dipendenze funzionali definite su di essa, ci interessa generare una decomposizione della relazione che contenga solo relazioni in forma normale e soddisfi le qualità di decomposizione senza perdita e conservazione delle dipendenze.\\
Poiché, come abbiamo visto, questo obiettivo non è sempre raggiungibile per la forma normale di Boyce e Codd, lo perseguiremo per la terza forma normale.\\\\
In linea di massima, il procedimento è quello già illustrato informalmente: definire una relazione per ciascun gruppo di dipendenze funzionali fra loro strettamente correlate.\\
Il procedimento va formalizzato per definire bene l'insieme di dipendenze di interesse e completato con una verifica finale, che può portare a un passo aggiuntivo.

\subsection{Implicazione di dipendenze funzionali}
Diciamo che un insieme di dipendenze funzionali $F$ \textbf{implica} un'altra dipendenza $f$ se ogni relazione che soddisfa tutte le dipendenze in $F$ soddisfa anche $f$.
\subsubsection{Chiusura di un insieme\\
Dati $F$ e $f$, come verifichiamo se $F$ implica $f$?}
Per procedere definiamo un concetto molto utile. Siano dati uno schema di relazione $R(U)$ e un insieme di dipendenze funzionali $F$ definite sugli attributi in $U$. 
Sia $X$ un insieme di attributi contenuti in $U$ (cioè $X \subseteq U$).\\
La \textbf{chiusura} di $X$ rispetto ad $F$, indicata con $X_F^+$, è l'insieme degli attributi che dipendono funzionalmente da $X$ (esplicitamente o implicitamente):
    \begin{equation}\begin{aligned}
        X_F^+ = \{ A: A \in U \wedge F \text{ implica } X \rightarrow A \}
    \end{aligned}\end{equation}
Questo insieme può essere molto utile: se vogliamo vedere se $X \rightarrow A$ è implicata da $F$, basta vedere se $A$ appartiene a $X_F^+$, a patto di saper calcolare quest'ultimo.\\
In effetti, questa è una strada valida, in quanto esiste un algoritmo che ci permette di calcolare $X_F^+$.\\\\
\textbf{Input}: un insieme $X$ di attributi e un insieme $F$ di dipendenze\\
\textbf{Output}: un insieme $X_P$ di attributi
    \begin{enumerate}
        \item{Inizializziamo $X_P$ con l'insieme di input $X$}
        \item{Esaminiamo le dipendenze in $F$: se esiste una dipendenza $Y \rightarrow A$ con $Y \subseteq X_P$ e $A \neq X_P$ allora aggiungiamo $A$ a $X_P$}
        \item{Ripetiamo il passo 2 fino al momento in cui non vi sono ulteriori attributi che possono essere aggiunti $X_P$}
    \end{enumerate}
Il concetto di chiusura è utile anche per formalizzare il concetto di dipendenza funzionale e quello di chiave: un insieme di attributi $K$ è chiave per uno schema di relazione $R(U)$ su cui è definito un insieme di dipendenze funzionali $F$ se $F$ implica $K \rightarrow U$. Di conseguenza, l'algoritmo appena mostrato può essere utilizzato per verificare se un insieme è chiave.
\subsubsection{Esempio}
Consideriamo la seguente relazione:
    \begin{center}\begin{tabular}{|c|c|c|c|c|}\hline
        \textbf{Impiegato} & \textbf{Stipendio} & \textbf{Progetto} & 
        \textbf{Bilancio} & \textbf{Funzione} \\ \hline
        Rossi & 20.000 & Marte & 2.000 & Tecnico \\ \hline
        Verdi & 35.000 & Giove & 15.000 & Progettista \\ \hline
        Verdi & 35.000 & Venere & 15.000 & Progettista \\ \hline
        Neri & 55.000 & Venere & 15.000 & Direttore \\ \hline
        Neri & 55.000 & Giove & 15.000 & Consulente \\ \hline
        Neri & 55.000 & Marte & 2.000 & Consulente \\ \hline
        Mori & 48.000 & Marte & 2.000 & Direttore \\ \hline
        Mori & 48.000 & Venere & 15.000 & Progettista \\ \hline
        Bianchi & 48.000 & Venere & 15.000 & Progettista \\ \hline
        Bianchi & 48.000 & Giove & 15.000 & Direttore \\ \hline
    \end{tabular}\end{center}
Indichiamo gli attributi di questo schema con le rispettive iniziali.\\
Possiamo verificare che gli attributi $IP$ formano una chiave, in quanto:
    \begin{equation}\begin{aligned}
        IP^+ = ISPBF \\
        I^+ = IS\\
        P^+ = PB
    \end{aligned}\end{equation}
La prima uguaglianza dimostra che $IP$ è superchiave, le ultime due che nessun sottoinsieme proprio di $IP$ è superchiave.\\\\
Il calcolo di $IP^+$ si esegue inizializzando l'insieme di lavoro a $IP$ e aggiungendo (in qualunque ordine):
    \begin{itemize}
        \item{$S$ utilizzando $I \rightarrow S$}
        \item{$B$ utilizzando $P \rightarrow B$}
        \item{$F$ utilizzando $IP \rightarrow F$}
    \end{itemize}
Invece, $I^+$ si calcola partendo da $I$ e aggiungendo solo $S$ (utilizzando $I \rightarrow S$); le altre due dipendenze non sono utilizzabili, perché $P$ non appartiene all'insieme di lavoro.

\subsection{Coperture di insiemi di dipendenze funzionali}
Può essere utile sostituire a un insieme di dipendenze funzionali un altro che specifichi, nella sostanza, le stesse proprietà, ma che sia più semplice da gestire.\\
Due insiemi di dipendenze funzionali $F_1$ e $F_2$ sono \textbf{equivalenti} se $F_1$ implica ciascuna dipendenza in $F_2$ e viceversa.\\
Se due insiemi sono equivalenti, diciamo anche che ognuno è \textbf{copertura} dell'altro.\\
Si può dimostrare che, dati due insiemi $F_1$ e $F_2$ equivalenti, una relazione soddisfa $F_1$ se e solo se essa soddisfa $F_2$. Questa proprietà giustifica, quindi l'uso del termine \textbf{equivalenza} e la possibilità di utilizzare, dato un insieme di dipendenze, un altro, a esso equivalente, ma più semplice, per esempio con meno dipendenze o meno attributi.\\
Diciamo che un insieme $F$ è:
    \begin{itemize}
        \item{\textbf{Non ridondante}: se non esiste dipendenza $f \in F$ tale che $F - \{f\}$ implica $f$.}
        \item{\textbf{Ridotto}: se non è ridondante e non esiste un insieme $F'$ equivalente a $F$ ottenuto eliminando attributi dai primi membri di una o più dipendenze di $F$.}
    \end{itemize}
Avendo già visto come si verifica l'implicazione, possiamo dire che il calcolo di una copertura non ridondante e di una ridotta, dato un insieme di dipendenze è abbastanza semplice, in quanto entrambe le definizioni si basano sul concetto di implicazione.\\
Per \textbf{trovare una copertura non ridondante} è sufficiente esaminare ripetutamente le dipendenze dell'insieme dato, eliminando quelle implicate da altre, fermandosi quando non ve ne sono più; l'insieme rimasto è una copertura non ridondante di quello iniziale.\\
Per \textbf{trovare una copertura ridotta}, per un qualunque insieme di dipendenze funzionali, possiamo procedere in tre passi:
    \begin{itemize}
        \item{Sostituiamo l'insieme dato con quello equivalente che ha tutti i secondi membri costituiti da singoli attributi}
        \item{Eliminiamo le dipendenze ridondanti}
        \item{Per ogni dipendenza verifichiamo se esistono attributi eliminabili dal primo membro}
    \end{itemize}

\subsubsection{Esempio}
Consideriamo alcuni insiemi di dipendenze:
    \begin{equation}\begin{aligned}
        F_1 = \{  A \rightarrow B, AB \rightarrow C, A \rightarrow C  \}\\
        F_2 = \{  A \rightarrow B, AB \rightarrow C \}\\
        F_3 = \{  A \rightarrow B, A \rightarrow C  \}\\
    \end{aligned}\end{equation}
Notiamo che:
    \begin{itemize}
        \item{$F_1$ è ridondante, perché $\{A \rightarrow B, AB \rightarrow C\}$ implica $A \rightarrow C$: $F_1$ è equivalente a $F_2$}
        \item{$F_2$ è non ridondante ma non è ridotto, perché $B$ può essere eliminato dal primo membro della seconda dipendenza: $F_2$ è equivalente a $F_3$}
        \item{$F_3$ è ridotto}
    \end{itemize}

\subsection{Sintesi di schemi in terza forma normale}
Dopo aver esaminato il concetto di copertura, possiamo mostrare come ottenere, in modo algoritmico una decomposizione in terza forma normale (che soddisfi le proprietà di conservazione delle dipendenze e decomposizione senza perdita) per un qualunque schema.\\
Ricordiamo la definizione di \textbf{terza forma normale}: uno schema di relazione $R(U)$ con il suo insieme di dipendenze funzionali $F$ è in terza forma normale se, per ogni dipendenza funzionale non banale $X \rightarrow A \in F$, almeno una delle seguenti condizioni è verificata:
    \begin{itemize}
        \item{$X$ contiene una chiave $K$ di $r$: cioè $X_F^+ = U$}
        \item{$A$ è contenuto in almeno una chiave di $r$: esiste un insieme di attributi $K \subseteq U$ tale che $K_F^+ = U$ e $(K-A)_F^+ \subset U$}
    \end{itemize}
L'algoritmo per la decomposizione procede come segue:
    \begin{enumerate}
        \item{Viene calcolata una copertura ridotta $G$ di $F$}
        \item{$G$ viene partizionato in sottoinsiemi $G_1, ..., G_k$ tali che a ogni insieme appartengano dipendenze che hanno primi membri con la stessa chiusura.\\
        Cioè: $X \rightarrow A$ e $Y \rightarrow B$ appartengono alla stessa partizione se e solo se $X_G^+ = Y_G^+$}
        \item{Viene costruito un insieme $\mathcal{U}$ di sottoinsiemi di $U$, uno per ciascuna partizione di dipendenze, con tutti gli attributi coinvolti nella partizione.}
        \item{Se un elemento di $\mathcal{U}$ è propriamente contenuto in un altro, allora esso viene eliminato da $\mathcal{U}$.}
        \item{Viene costruito uno schema di basi dati con uno schema di relazione $R_i(U_i)$ per ciascun elemento:\\
        $U_i \in \mathcal{U}$ con associate le dipendenze in $G$ i cui attributi sono tutti contenuti in $U_i$.}
        \item{Se nessuno degli $U_i$ costituisce una chiave per la relazione originaria $R(U)$, allora viene calcolata una chiave $K$ di $R(U)$ e viene aggiunto allo schema generato al passo precedente uno schema di relazione sugli attributi $K$, senza dipendenze.}
    \end{enumerate}
Questo algoritmo va spesso sotto  il nome di \textbf{algoritmo di sintesi di schemi in terza forma normale}, perché costruisce lo schema finale a partire dalle dipendenze.

